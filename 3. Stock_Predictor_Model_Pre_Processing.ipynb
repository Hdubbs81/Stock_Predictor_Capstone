{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1980f83d",
   "metadata": {},
   "source": [
    "# 3. Data Pre Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6809181b",
   "metadata": {},
   "source": [
    "<a id=\"contents\"></a>\n",
    "# Table of Contents  \n",
    "3.1. [Introduction](#introduction) <br>\n",
    "3.2. [Imports](#imports)  <br>\n",
    "3.3. [Data Processing](#process)<br>\n",
    "3.4. [Scale the Data](#data)<br>\n",
    "3.5. [Create LSTM Sequences](#create)<br>\n",
    "3.6. [Data Splitting](#split)<br>\n",
    "3.7. [Save Updated Dataframe](#save)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cbb69c9",
   "metadata": {},
   "source": [
    "## 3.1 Introduction<a id=\"introduction\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d0ce9f3",
   "metadata": {},
   "source": [
    "The goal of this notebook is to create a cleaned development dataset to be used to complete the modeling step of my project."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b908f48",
   "metadata": {},
   "source": [
    "## 3.2 Imports<a id=\"imports\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b32c7849",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.dates as mdates\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns \n",
    "import os\n",
    "import csv\n",
    "import datetime as dt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4139df9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/Users/heatheradler/Documents/GitHub/Springboard/Springboard_Projects/Stock_Predictor_Capstone/Concated_Dataframe.csv')\n",
    "df = df[df['stock_symbol'].isin(['EL','ULTA','COTY','ELF'])]\n",
    "formulas_to_keep = ['stock_symbol','Date', 'Open', 'High', 'Low', 'Close', 'Volume', 'Dividends', 'Stock Splits', 'EMA_10', 'PSARl_0.02_0.2', 'PSARs_0.02_0.2', 'BBL_5_2.0', 'BBM_5_2.0', 'BBU_5_2.0', 'ISA_9', 'ISB_26', 'ITS_9', 'IKS_26', 'ICS_26']\n",
    "df = df[formulas_to_keep]\n",
    "df.head()\n",
    "scalers = pickle.load(open('scalers.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "edb086e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Date = pd.to_datetime(df.Date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e662fa96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 15880 entries, 0 to 15879\n",
      "Data columns (total 20 columns):\n",
      " #   Column          Non-Null Count  Dtype         \n",
      "---  ------          --------------  -----         \n",
      " 0   stock_symbol    15880 non-null  object        \n",
      " 1   Date            15880 non-null  datetime64[ns]\n",
      " 2   Open            15880 non-null  float64       \n",
      " 3   High            15880 non-null  float64       \n",
      " 4   Low             15880 non-null  float64       \n",
      " 5   Close           15880 non-null  float64       \n",
      " 6   Volume          15880 non-null  int64         \n",
      " 7   Dividends       15880 non-null  float64       \n",
      " 8   Stock Splits    15880 non-null  float64       \n",
      " 9   EMA_10          15880 non-null  float64       \n",
      " 10  PSARl_0.02_0.2  15880 non-null  float64       \n",
      " 11  PSARs_0.02_0.2  15880 non-null  float64       \n",
      " 12  BBL_5_2.0       15880 non-null  float64       \n",
      " 13  BBM_5_2.0       15880 non-null  float64       \n",
      " 14  BBU_5_2.0       15880 non-null  float64       \n",
      " 15  ISA_9           15880 non-null  float64       \n",
      " 16  ISB_26          15880 non-null  float64       \n",
      " 17  ITS_9           15880 non-null  float64       \n",
      " 18  IKS_26          15880 non-null  float64       \n",
      " 19  ICS_26          15880 non-null  float64       \n",
      "dtypes: datetime64[ns](1), float64(17), int64(1), object(1)\n",
      "memory usage: 2.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8947b52",
   "metadata": {},
   "source": [
    "## 3.3 Data Pre-processing<a id=\"process\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cf7bd95c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                Open      High       Low     Close    Volume stock_symbol\n",
      "Date                                                                     \n",
      "1995-11-17  6.086093  6.530846  6.062685  6.460622  35659200           EL\n",
      "1995-11-20  6.437214  6.601070  6.132909  6.226542   8434000           EL\n",
      "1995-11-21  6.179726  6.203134  5.945645  6.109501   6440000           EL\n",
      "1995-11-22  6.086094  6.390399  6.086094  6.296767   3480800           EL\n",
      "1995-11-24  6.343582  6.530847  6.320174  6.530847   1279200           EL\n"
     ]
    }
   ],
   "source": [
    "# Function to preprocess data\n",
    "def preprocess_data(df):\n",
    "    df = df[['Date', 'Open', 'High', 'Low', 'Close', 'Volume', 'stock_symbol']].copy()\n",
    "    df.set_index('Date', inplace=True)\n",
    "    df = df.sort_index()\n",
    "    return df\n",
    "\n",
    "# Preprocess the data\n",
    "df_1 = preprocess_data(df)\n",
    "print(df_1.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2863581d",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor_df = df_1.drop('Close', axis=1)\n",
    "target_df = df_1[['Close']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5584ff3",
   "metadata": {},
   "source": [
    "## 3.4 Scale the Data<a id=\"data\"></a>\n",
    "\n",
    "Standardization (Z-score normalization) is used to transform the data to have a mean of 0 and a standard deviation of 1. This is to ensure optimal performance and stability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4e3b3784",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Close</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1995-11-17</th>\n",
       "      <td>6.460622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995-11-20</th>\n",
       "      <td>6.226542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995-11-21</th>\n",
       "      <td>6.109501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995-11-22</th>\n",
       "      <td>6.296767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995-11-24</th>\n",
       "      <td>6.530847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-03-27</th>\n",
       "      <td>513.520020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-03-28</th>\n",
       "      <td>196.029999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-03-28</th>\n",
       "      <td>154.149994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-03-28</th>\n",
       "      <td>522.880005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-03-28</th>\n",
       "      <td>11.960000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15880 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Close\n",
       "Date                  \n",
       "1995-11-17    6.460622\n",
       "1995-11-20    6.226542\n",
       "1995-11-21    6.109501\n",
       "1995-11-22    6.296767\n",
       "1995-11-24    6.530847\n",
       "...                ...\n",
       "2024-03-27  513.520020\n",
       "2024-03-28  196.029999\n",
       "2024-03-28  154.149994\n",
       "2024-03-28  522.880005\n",
       "2024-03-28   11.960000\n",
       "\n",
       "[15880 rows x 1 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "54d72061",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate Close from the df:\n",
    "predictor_df = df_1.drop('Close', axis=1)\n",
    "target_df = df_1[['Close', 'stock_symbol']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b59578ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_data(df_1):\n",
    "    scalers = {}\n",
    "    scaled_data = pd.DataFrame()\n",
    "    \n",
    "    for stock in df_1['stock_symbol'].unique():\n",
    "        stock_data = df_1[df_1['stock_symbol'] == stock]\n",
    "        scaler = StandardScaler()\n",
    "        scaled_values = scaler.fit_transform(stock_data.drop(columns='stock_symbol'))\n",
    "        scaled_df = pd.DataFrame(scaled_values, columns=stock_data.columns[:-1], index=stock_data.index)\n",
    "        scaled_df['stock_symbol'] = stock\n",
    "        scalers[stock] = scaler\n",
    "        scaled_data = pd.concat([scaled_data, scaled_df])\n",
    "        \n",
    "    return scaled_data, scalers\n",
    "\n",
    "\n",
    "# Scale the data for our predictor variables:\n",
    "predictor_scaled_df, predictor_scalers = scale_data(predictor_df)\n",
    "# Scale the data for our target variable:\n",
    "target_scaled_df, target_scaler = scale_data(target_df) \n",
    "\n",
    "\n",
    "# Save the scalers:\n",
    "with open('/Users/heatheradler/Documents/GitHub/Springboard/Springboard_Projects/Stock_Predictor_Capstone/predictor_scalers.pkl', 'wb') as f:\n",
    "    pickle.dump(predictor_scalers, f)\n",
    "    \n",
    "with open('/Users/heatheradler/Documents/GitHub/Springboard/Springboard_Projects/Stock_Predictor_Capstone/target_scaler.pkl', 'wb') as f:\n",
    "    pickle.dump(target_scaler, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "db29ecb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Close</th>\n",
       "      <th>stock_symbol</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1995-11-17</th>\n",
       "      <td>-0.781448</td>\n",
       "      <td>EL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995-11-20</th>\n",
       "      <td>-0.784352</td>\n",
       "      <td>EL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995-11-21</th>\n",
       "      <td>-0.785804</td>\n",
       "      <td>EL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995-11-22</th>\n",
       "      <td>-0.783481</td>\n",
       "      <td>EL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995-11-24</th>\n",
       "      <td>-0.780577</td>\n",
       "      <td>EL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-03-22</th>\n",
       "      <td>4.332822</td>\n",
       "      <td>ELF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-03-25</th>\n",
       "      <td>4.189170</td>\n",
       "      <td>ELF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-03-26</th>\n",
       "      <td>4.131813</td>\n",
       "      <td>ELF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-03-27</th>\n",
       "      <td>4.091249</td>\n",
       "      <td>ELF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-03-28</th>\n",
       "      <td>4.085565</td>\n",
       "      <td>ELF</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15880 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Close stock_symbol\n",
       "Date                             \n",
       "1995-11-17 -0.781448           EL\n",
       "1995-11-20 -0.784352           EL\n",
       "1995-11-21 -0.785804           EL\n",
       "1995-11-22 -0.783481           EL\n",
       "1995-11-24 -0.780577           EL\n",
       "...              ...          ...\n",
       "2024-03-22  4.332822          ELF\n",
       "2024-03-25  4.189170          ELF\n",
       "2024-03-26  4.131813          ELF\n",
       "2024-03-27  4.091249          ELF\n",
       "2024-03-28  4.085565          ELF\n",
       "\n",
       "[15880 rows x 2 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_scaled_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "19011dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pickle\n",
    "\n",
    "# Function to create sequences for LSTM\n",
    "def create_sequences(predictor_data, target_data, seq_length, stock_symbol):\n",
    "    sequences = []\n",
    "    labels = []\n",
    "    stock_symbols = []\n",
    "    \n",
    "    for i in range(len(predictor_data) - seq_length):\n",
    "        seq = predictor_data[i:i + seq_length]\n",
    "        label = target_data[i + seq_length]  # Use 'Close' as target variable\n",
    "        sequences.append(seq)\n",
    "        labels.append(label)\n",
    "        stock_symbols.append(stock_symbol)\n",
    "        \n",
    "    return np.array(sequences), np.array(labels), np.array(stock_symbols)\n",
    "\n",
    "# Define the sequence length\n",
    "SEQ_LENGTH = 50\n",
    "\n",
    "# Assuming predictor_scaled_df and target_scaled_df are already scaled\n",
    "# and both have a 'stock_symbol' column.\n",
    "\n",
    "# Filter by stock symbol and create sequences\n",
    "all_sequences = []\n",
    "all_labels = []\n",
    "all_stock_symbols = []\n",
    "\n",
    "for stock in predictor_scaled_df['stock_symbol'].unique():\n",
    "    predictor_stock_data = predictor_scaled_df[predictor_scaled_df['stock_symbol'] == stock].drop(columns='stock_symbol').values\n",
    "    target_stock_data = target_scaled_df[target_scaled_df['stock_symbol'] == stock]['Close'].values\n",
    "    sequences, labels, stock_symbols = create_sequences(predictor_stock_data, target_stock_data, SEQ_LENGTH, stock)\n",
    "    all_sequences.extend(sequences)\n",
    "    all_labels.extend(labels)\n",
    "    all_stock_symbols.extend(stock_symbols)\n",
    "\n",
    "all_sequences = np.array(all_sequences)\n",
    "all_labels = np.array(all_labels)\n",
    "all_stock_symbols = np.array(all_stock_symbols)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cb209d4",
   "metadata": {},
   "source": [
    "## 3.5 Create LSTM Sequences<a id=\"create\"></a>\n",
    "\n",
    "Long Short-Term Memory (LSTM) models are designed to work with sequential data, therefore sequences must be created for training. Creating LSTM sequences is a crucial step in preparing data for stock market prediction because it helps the model understand the patterns and trends over time. Specifically, creating LSTM sequences are important for: \n",
    "\n",
    "1) Understanding Trends: Stock prices are influenced by their historical values. By creating sequences, we allow the model to look at a series of past prices and learn how these prices evolve over time.\n",
    "\n",
    "2) Capturing Patterns: Financial data often shows specific patterns, like trends or cycles. Sequences help the model recognize these patterns by providing context from previous days or weeks.\n",
    "\n",
    "3) Improving Predictions: Just looking at a single day's data isn't enough to make accurate predictions. Sequences give the model a broader view, allowing it to make better-informed predictions about future prices.\n",
    "\n",
    "4) Handling Time Dependency: Stock prices are inherently time-dependent; today's price is related to yesterday's price. Sequences ensure that this time dependency is captured in the model, which is crucial for making accurate forecasts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7e2cbb63",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sequences = np.array(all_sequences)\n",
    "all_labels = np.array(all_labels)\n",
    "all_stock_symbols = np.array(all_stock_symbols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c46b6b2d",
   "metadata": {},
   "source": [
    "## 3.6 Data Splitting<a id=\"split\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5d04caf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the data into training and test sets\n",
    "X_train, X_test, y_train, y_test, stock_symbols_train, stock_symbols_test = train_test_split(all_sequences, all_labels, all_stock_symbols, test_size=0.2, shuffle=False)\n",
    "\n",
    "# Save the symbols for test set\n",
    "#np.save('symbols_test.npy', symbols_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cf14496",
   "metadata": {},
   "source": [
    "## 3.7 Save Updated Dataframe<a id=\"save\"></a>\n",
    "\n",
    "The training and test sets must be saved as numpy arrays to be imported into the Modeling notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9ae2baad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved successfully.\n"
     ]
    }
   ],
   "source": [
    "# save updated dataframe\n",
    "df_1.to_csv('/Users/heatheradler/Documents/GitHub/Springboard/Springboard_Projects/Stock_Predictor_Capstone/Updated_df.csv')\n",
    "\n",
    "print(\"Data saved successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "77a86bba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved successfully.\n"
     ]
    }
   ],
   "source": [
    "# Save the data to .npy files\n",
    "np.save('X_train.npy', X_train, allow_pickle=True)\n",
    "np.save('X_test.npy', X_test, allow_pickle=True)\n",
    "np.save('y_train.npy', y_train, allow_pickle=True)\n",
    "np.save('y_test.npy', y_test, allow_pickle=True)\n",
    "np.save('stock_symbols_train.npy', stock_symbols_train, allow_pickle=True)\n",
    "np.save('stock_symbols_test.npy', stock_symbols_test, allow_pickle=True)\n",
    "\n",
    "print(\"Data saved successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc1acecc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
