{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1980f83d",
   "metadata": {},
   "source": [
    "# 3. Data Pre Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6809181b",
   "metadata": {},
   "source": [
    "<a id=\"contents\"></a>\n",
    "# Table of Contents  \n",
    "3.1. [Introduction](#introduction) <br>\n",
    "3.2. [Imports](#imports)  <br>\n",
    "3.3. [Data Processing](#process)<br>\n",
    "3.4. [Scale the Data](#data)<br>\n",
    "3.5. [Create LSTM Sequences](#create)<br>\n",
    "3.6. [Data Splitting](#split)<br>\n",
    "3.7. [Save Updated Dataframe](#save)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cbb69c9",
   "metadata": {},
   "source": [
    "## 3.1 Introduction<a id=\"introduction\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d0ce9f3",
   "metadata": {},
   "source": [
    "The goal of this notebook is to create a cleaned development dataset to be used to complete the modeling step of my project."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b908f48",
   "metadata": {},
   "source": [
    "## 3.2 Imports<a id=\"imports\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b32c7849",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.dates as mdates\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns \n",
    "import os\n",
    "import csv\n",
    "import datetime as dt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4139df9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stock_symbol</th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Dividends</th>\n",
       "      <th>Stock Splits</th>\n",
       "      <th>EMA_10</th>\n",
       "      <th>PSARl_0.02_0.2</th>\n",
       "      <th>PSARs_0.02_0.2</th>\n",
       "      <th>BBL_5_2.0</th>\n",
       "      <th>BBM_5_2.0</th>\n",
       "      <th>BBU_5_2.0</th>\n",
       "      <th>ISA_9</th>\n",
       "      <th>ISB_26</th>\n",
       "      <th>ITS_9</th>\n",
       "      <th>IKS_26</th>\n",
       "      <th>ICS_26</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ULTA</td>\n",
       "      <td>2007-10-25</td>\n",
       "      <td>28.728543</td>\n",
       "      <td>34.612703</td>\n",
       "      <td>28.570313</td>\n",
       "      <td>29.490023</td>\n",
       "      <td>7487306</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29.490023</td>\n",
       "      <td>29.490023</td>\n",
       "      <td>29.490023</td>\n",
       "      <td>29.490023</td>\n",
       "      <td>29.490023</td>\n",
       "      <td>29.490023</td>\n",
       "      <td>29.490023</td>\n",
       "      <td>29.490023</td>\n",
       "      <td>29.490023</td>\n",
       "      <td>29.490023</td>\n",
       "      <td>26.008974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ULTA</td>\n",
       "      <td>2007-10-26</td>\n",
       "      <td>30.211945</td>\n",
       "      <td>32.615056</td>\n",
       "      <td>28.926331</td>\n",
       "      <td>31.645901</td>\n",
       "      <td>1625582</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29.882000</td>\n",
       "      <td>28.570313</td>\n",
       "      <td>29.882000</td>\n",
       "      <td>29.882000</td>\n",
       "      <td>29.882000</td>\n",
       "      <td>29.882000</td>\n",
       "      <td>29.882000</td>\n",
       "      <td>29.882000</td>\n",
       "      <td>29.882000</td>\n",
       "      <td>29.882000</td>\n",
       "      <td>25.563955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ULTA</td>\n",
       "      <td>2007-10-29</td>\n",
       "      <td>32.130481</td>\n",
       "      <td>34.612704</td>\n",
       "      <td>32.130481</td>\n",
       "      <td>34.316025</td>\n",
       "      <td>668513</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.688187</td>\n",
       "      <td>28.570313</td>\n",
       "      <td>30.688187</td>\n",
       "      <td>30.688187</td>\n",
       "      <td>30.688187</td>\n",
       "      <td>30.688187</td>\n",
       "      <td>30.688187</td>\n",
       "      <td>30.688187</td>\n",
       "      <td>30.688187</td>\n",
       "      <td>30.688187</td>\n",
       "      <td>26.246321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ULTA</td>\n",
       "      <td>2007-10-30</td>\n",
       "      <td>34.830269</td>\n",
       "      <td>35.206062</td>\n",
       "      <td>32.634834</td>\n",
       "      <td>35.037945</td>\n",
       "      <td>455543</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>31.479052</td>\n",
       "      <td>28.812009</td>\n",
       "      <td>31.479052</td>\n",
       "      <td>31.479052</td>\n",
       "      <td>31.479052</td>\n",
       "      <td>31.479052</td>\n",
       "      <td>31.479052</td>\n",
       "      <td>31.479052</td>\n",
       "      <td>31.479052</td>\n",
       "      <td>31.479052</td>\n",
       "      <td>27.185806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ULTA</td>\n",
       "      <td>2007-10-31</td>\n",
       "      <td>35.987321</td>\n",
       "      <td>35.987321</td>\n",
       "      <td>32.585388</td>\n",
       "      <td>33.821556</td>\n",
       "      <td>393584</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>31.904962</td>\n",
       "      <td>29.195652</td>\n",
       "      <td>31.904962</td>\n",
       "      <td>28.800881</td>\n",
       "      <td>32.862290</td>\n",
       "      <td>36.923698</td>\n",
       "      <td>31.904962</td>\n",
       "      <td>31.904962</td>\n",
       "      <td>31.904962</td>\n",
       "      <td>31.904962</td>\n",
       "      <td>27.670383</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  stock_symbol        Date       Open       High        Low      Close  \\\n",
       "0         ULTA  2007-10-25  28.728543  34.612703  28.570313  29.490023   \n",
       "1         ULTA  2007-10-26  30.211945  32.615056  28.926331  31.645901   \n",
       "2         ULTA  2007-10-29  32.130481  34.612704  32.130481  34.316025   \n",
       "3         ULTA  2007-10-30  34.830269  35.206062  32.634834  35.037945   \n",
       "4         ULTA  2007-10-31  35.987321  35.987321  32.585388  33.821556   \n",
       "\n",
       "    Volume  Dividends  Stock Splits     EMA_10  PSARl_0.02_0.2  \\\n",
       "0  7487306        0.0           0.0  29.490023       29.490023   \n",
       "1  1625582        0.0           0.0  29.882000       28.570313   \n",
       "2   668513        0.0           0.0  30.688187       28.570313   \n",
       "3   455543        0.0           0.0  31.479052       28.812009   \n",
       "4   393584        0.0           0.0  31.904962       29.195652   \n",
       "\n",
       "   PSARs_0.02_0.2  BBL_5_2.0  BBM_5_2.0  BBU_5_2.0      ISA_9     ISB_26  \\\n",
       "0       29.490023  29.490023  29.490023  29.490023  29.490023  29.490023   \n",
       "1       29.882000  29.882000  29.882000  29.882000  29.882000  29.882000   \n",
       "2       30.688187  30.688187  30.688187  30.688187  30.688187  30.688187   \n",
       "3       31.479052  31.479052  31.479052  31.479052  31.479052  31.479052   \n",
       "4       31.904962  28.800881  32.862290  36.923698  31.904962  31.904962   \n",
       "\n",
       "       ITS_9     IKS_26     ICS_26  \n",
       "0  29.490023  29.490023  26.008974  \n",
       "1  29.882000  29.882000  25.563955  \n",
       "2  30.688187  30.688187  26.246321  \n",
       "3  31.479052  31.479052  27.185806  \n",
       "4  31.904962  31.904962  27.670383  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('/Users/heatheradler/Documents/GitHub/Springboard/Springboard_Projects/Stock_Predictor_Capstone/Concated_Dataframe.csv')\n",
    "df = df[df['stock_symbol'].isin(['EL','ULTA','COTY','ELF'])]\n",
    "formulas_to_keep = ['stock_symbol','Date', 'Open', 'High', 'Low', 'Close','Volume', 'Dividends', 'Stock Splits', 'EMA_10', 'PSARl_0.02_0.2', 'PSARs_0.02_0.2', 'BBL_5_2.0', 'BBM_5_2.0', 'BBU_5_2.0', 'ISA_9', 'ISB_26', 'ITS_9', 'IKS_26', 'ICS_26']\n",
    "df = df[formulas_to_keep]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "edb086e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Date = pd.to_datetime(df.Date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e662fa96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 15880 entries, 0 to 15879\n",
      "Data columns (total 20 columns):\n",
      " #   Column          Non-Null Count  Dtype         \n",
      "---  ------          --------------  -----         \n",
      " 0   stock_symbol    15880 non-null  object        \n",
      " 1   Date            15880 non-null  datetime64[ns]\n",
      " 2   Open            15880 non-null  float64       \n",
      " 3   High            15880 non-null  float64       \n",
      " 4   Low             15880 non-null  float64       \n",
      " 5   Close           15880 non-null  float64       \n",
      " 6   Volume          15880 non-null  int64         \n",
      " 7   Dividends       15880 non-null  float64       \n",
      " 8   Stock Splits    15880 non-null  float64       \n",
      " 9   EMA_10          15880 non-null  float64       \n",
      " 10  PSARl_0.02_0.2  15880 non-null  float64       \n",
      " 11  PSARs_0.02_0.2  15880 non-null  float64       \n",
      " 12  BBL_5_2.0       15880 non-null  float64       \n",
      " 13  BBM_5_2.0       15880 non-null  float64       \n",
      " 14  BBU_5_2.0       15880 non-null  float64       \n",
      " 15  ISA_9           15880 non-null  float64       \n",
      " 16  ISB_26          15880 non-null  float64       \n",
      " 17  ITS_9           15880 non-null  float64       \n",
      " 18  IKS_26          15880 non-null  float64       \n",
      " 19  ICS_26          15880 non-null  float64       \n",
      "dtypes: datetime64[ns](1), float64(17), int64(1), object(1)\n",
      "memory usage: 2.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8947b52",
   "metadata": {},
   "source": [
    "## 3.3 Data Pre-processing<a id=\"process\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cf7bd95c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                Open      High       Low     Close    Volume stock_symbol\n",
      "Date                                                                     \n",
      "1995-11-17  6.086093  6.530846  6.062685  6.460622  35659200           EL\n",
      "1995-11-20  6.437214  6.601070  6.132909  6.226542   8434000           EL\n",
      "1995-11-21  6.179726  6.203134  5.945645  6.109501   6440000           EL\n",
      "1995-11-22  6.086094  6.390399  6.086094  6.296767   3480800           EL\n",
      "1995-11-24  6.343582  6.530847  6.320174  6.530847   1279200           EL\n"
     ]
    }
   ],
   "source": [
    "# Function to preprocess data\n",
    "def preprocess_data(df):\n",
    "    df = df[['Date', 'Open', 'High', 'Low', 'Close', 'Volume', 'stock_symbol']].copy()\n",
    "    df.set_index('Date', inplace=True)\n",
    "    df = df.sort_index()\n",
    "    return df\n",
    "\n",
    "# Preprocess the data\n",
    "df_1 = preprocess_data(df)\n",
    "print(df_1.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5584ff3",
   "metadata": {},
   "source": [
    "## 3.4 Scale the Data<a id=\"data\"></a>\n",
    "\n",
    "Standardization (Z-score normalization) is used to transform the data to have a mean of 0 and a standard deviation of 1. This is to ensure optimal performance and stability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b59578ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                Open      High       Low     Close     Volume stock_symbol\n",
      "Date                                                                      \n",
      "1995-11-17 -0.785894 -0.780930 -0.785739 -0.781448  18.654287           EL\n",
      "1995-11-20 -0.781538 -0.780069 -0.784858 -0.784352   3.551529           EL\n",
      "1995-11-21 -0.784733 -0.784949 -0.787208 -0.785804   2.445389           EL\n",
      "1995-11-22 -0.785894 -0.782653 -0.785445 -0.783481   0.803819           EL\n",
      "1995-11-24 -0.782700 -0.780930 -0.782508 -0.780577  -0.417485           EL\n"
     ]
    }
   ],
   "source": [
    "def scale_data(df_1):\n",
    "    scalers = {}\n",
    "    scaled_data = pd.DataFrame()\n",
    "    \n",
    "    for stock in df_1['stock_symbol'].unique():\n",
    "        stock_data = df_1[df_1['stock_symbol'] == stock]\n",
    "        scaler = StandardScaler()\n",
    "        scaled_values = scaler.fit_transform(stock_data.drop(columns='stock_symbol'))\n",
    "        scaled_df = pd.DataFrame(scaled_values, columns=stock_data.columns[:-1], index=stock_data.index)\n",
    "        scaled_df['stock_symbol'] = stock\n",
    "        scalers[stock] = scaler\n",
    "        scaled_data = pd.concat([scaled_data, scaled_df])\n",
    "        \n",
    "    return scaled_data, scalers\n",
    "\n",
    "scaled_df, scalers = scale_data(df_1)\n",
    "print(scaled_df.head())\n",
    "\n",
    "# Save the scalers\n",
    "with open('/Users/heatheradler/Documents/GitHub/Springboard/Springboard_Projects/Stock_Predictor_Capstone/scalers.pkl', 'wb') as f:\n",
    "    pickle.dump(scalers, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "97e31e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scaler = StandardScaler()\n",
    "#scaled_values = scaler.fit_transform(df_1.drop('stock_symbol', axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "61e8d7d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the scalers\n",
    "#with open('/Users/heatheradler/Documents/GitHub/Springboard/Springboard_Projects/Stock_Predictor_Capstone/scaler.pkl', 'wb') as f:\n",
    "    #pickle.dump(scaler, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5bc6ce84",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scaled_df_2 = pd.DataFrame(scaled_values, columns=['Open', 'High', 'Low', 'Close', 'Volume'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "25ef7db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scaled_df_2.index = df_1.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d63569cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scaled_df_2['stock_symbol'] = df_1.stock_symbol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1af1188b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scaled_df_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "874de643",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.DataFrame(scaler.inverse_transform(scaled_values), columns=['Open', 'High', 'Low', 'Close', 'Volume'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cb209d4",
   "metadata": {},
   "source": [
    "## 3.5 Create LSTM Sequences<a id=\"create\"></a>\n",
    "\n",
    "Long Short-Term Memory (LSTM) models are designed to work with sequential data, therefore sequences must be created for training. Creating LSTM sequences is a crucial step in preparing data for stock market prediction because it helps the model understand the patterns and trends over time. Specifically, creating LSTM sequences are important for: \n",
    "\n",
    "1) Understanding Trends: Stock prices are influenced by their historical values. By creating sequences, we allow the model to look at a series of past prices and learn how these prices evolve over time.\n",
    "\n",
    "2) Capturing Patterns: Financial data often shows specific patterns, like trends or cycles. Sequences help the model recognize these patterns by providing context from previous days or weeks.\n",
    "\n",
    "3) Improving Predictions: Just looking at a single day's data isn't enough to make accurate predictions. Sequences give the model a broader view, allowing it to make better-informed predictions about future prices.\n",
    "\n",
    "4) Handling Time Dependency: Stock prices are inherently time-dependent; today's price is related to yesterday's price. Sequences ensure that this time dependency is captured in the model, which is crucial for making accurate forecasts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7e2cbb63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create sequences for LSTM\n",
    "def create_sequences(data, seq_length):\n",
    "    sequences = []\n",
    "    labels = []\n",
    "    stock_symbols = []\n",
    "    \n",
    "    for i in range(len(data) - seq_length):\n",
    "        seq = data[i:i + seq_length]\n",
    "        label = data[i + seq_length][0]  # Use 'Open' as target variable\n",
    "        sequences.append(seq)\n",
    "        labels.append(label)\n",
    "        stock_symbols.append(data[i + seq_length][-1])  # Store the stock symbol\n",
    "        \n",
    "    return np.array(sequences), np.array(labels), np.array(stock_symbols)\n",
    "\n",
    "# Define the sequence length\n",
    "SEQ_LENGTH = 50\n",
    "\n",
    "# Filter by stock symbol and create sequences\n",
    "all_sequences = []\n",
    "all_labels = []\n",
    "all_stock_symbols = []\n",
    "\n",
    "for stock in scaled_df['stock_symbol'].unique():\n",
    "    stock_data = scaled_df[scaled_df['stock_symbol'] == stock].values\n",
    "    sequences, labels, stock_symbols = create_sequences(stock_data, SEQ_LENGTH)\n",
    "    all_sequences.extend(sequences)\n",
    "    all_labels.extend(labels)\n",
    "    all_stock_symbols.extend(stock_symbols)\n",
    "\n",
    "all_sequences = np.array(all_sequences)\n",
    "all_labels = np.array(all_labels)\n",
    "all_stock_symbols = np.array(all_stock_symbols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c46b6b2d",
   "metadata": {},
   "source": [
    "## 3.6 Data Splitting<a id=\"split\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5d04caf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the data into training and test sets\n",
    "X_train, X_test, y_train, y_test, stock_symbols_train, stock_symbols_test = train_test_split(all_sequences, all_labels, all_stock_symbols, test_size=0.2, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cf14496",
   "metadata": {},
   "source": [
    "## 3.7 Save Updated Dataframe<a id=\"save\"></a>\n",
    "\n",
    "The training and test sets must be saved as numpy arrays to be imported into the Modeling notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9ae2baad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved successfully.\n"
     ]
    }
   ],
   "source": [
    "# save updated dataframe\n",
    "df_1.to_csv('/Users/heatheradler/Documents/GitHub/Springboard/Springboard_Projects/Stock_Predictor_Capstone/Updated_df.csv')\n",
    "\n",
    "print(\"Data saved successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "77a86bba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved successfully.\n"
     ]
    }
   ],
   "source": [
    "# Save the data to .npy files\n",
    "np.save('X_train.npy', X_train, allow_pickle=True)\n",
    "np.save('X_test.npy', X_test, allow_pickle=True)\n",
    "np.save('y_train.npy', y_train, allow_pickle=True)\n",
    "np.save('y_test.npy', y_test, allow_pickle=True)\n",
    "np.save('stock_symbols_train.npy', stock_symbols_train, allow_pickle=True)\n",
    "np.save('stock_symbols_test.npy', stock_symbols_test, allow_pickle=True)\n",
    "\n",
    "print(\"Data saved successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc1acecc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
